server:
  port: 9999

spring:
  mvc:
    pathmatch:
      matching-strategy: ant_path_matcher

  datasource:
    url: jdbc:mysql://localhost:3306/blog
    username: root
    password: root

  kafka:
    bootstrap-servers: 101.34.219.189:9092 # 指定 Kafka Broker 地址，可以设置多个，以逗号分隔
    # Kafka Producer 配置项
    producer:
      acks: 1 # 0-不应答。1-leader 应答。all-所有 leader 和 follower 应答。
      retries: 3 # 发送失败时，重试发送的次数
      key-serializer: org.apache.kafka.common.serialization.StringSerializer # 消息的 key 的序列化
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer # 消息的 value 的序列化
    #      batch-size: 16384 # 每次批量发送消息的最大数量
    #      buffer-memory: 33554432 # 每次批量发送消息的最大内存
    #      properties:
    #        linger:
    #          ms: 30000 # 批处理延迟时间上限。这里配置为 30 * 1000 ms 过后，不管是否消息数量是否到达 batch-size 或者消息大小到达 buffer-memory 后，都直接发送一次请求
    # Kafka Consumer 配置项
    consumer:
      auto-offset-reset: earliest # 设置消费者分组最初的消费进度为 earliest 。可参考博客 https://blog.csdn.net/lishuangzhe7047/article/details/74530417 理解
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        spring:
          json:
            trusted:
              packages: cn.zzy.kafka.message #  JsonDeserializer 在反序列化消息时，考虑到安全性，只反序列化成信任的 Message 类
    # Kafka Consumer Listener 监听器配置
    listener:
      missing-topics-fatal: false # 消费监听接口监听的主题不存在时，默认会报错。所以通过设置为 false ，解决报错

  redis:
    port: 6379
    host: 101.34.219.189
    database: 0 #redis数据库索引
    timeout: 5000ms # 与Redis 服务器建立连接的超时时间
    lettuce:
      pool:
        max-active: 100 #设置 Lettuce 连接池的最大活动连接数
        max-idle: 10 #设置 Lettuce 连接池的最大空闲连接数
        max-wait: -1ms #设置 Lettuce 连接池的最大等待时间，-1 表示无限等待
        min-idle: 2 #设置 Lettuce 连接池的最小空闲连接数
      shutdown-timeout: 100ms #设置 Lettuce 连接池关闭超时时间


